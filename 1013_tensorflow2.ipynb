{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn의 결과 : [[38.75927452]]\n",
      "tensorflow의 결과 : [[38.881004]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats   # 이상치 처리를 위해서 필요\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')  # warning 출력을 하지 않아요!\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('/Users/mac/notebook_dir/data/ozone.csv')\n",
    "\n",
    "taining_data = df\n",
    "\n",
    "x_data = taining_data[['Solar.R','Wind','Temp']]\n",
    "t_data = taining_data['Ozone']\n",
    "\n",
    "# 결측치 확인\n",
    "# 1. 독립변수에 대한 결측치 처리부터 하고 갈께요!!\n",
    "#    Solar.R에 7개의 결측치가 있는데 median으로 처리할께요!\n",
    "for col in x_data.columns:\n",
    "    col_median = np.nanmedian(x_data[col])\n",
    "    x_data[col].loc[x_data[col].isnull()] = col_median\n",
    "    \n",
    "# 2. 독립변수에 대한 이상치를 검출한 후 이 이상치는 mean처리할께요!\n",
    "zscore = 1.8\n",
    "\n",
    "for col in x_data.columns:\n",
    "    outliers = x_data[col][np.abs(stats.zscore(x_data[col])) > zscore]\n",
    "    col_mean = np.mean(x_data.loc[~x_data[col].isin(outliers),col])\n",
    "    x_data.loc[x_data[col].isin(outliers),col] = col_mean\n",
    "\n",
    "# 3. 정규화를 진행해요!\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_t = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(x_data.values)\n",
    "scaler_t.fit(t_data.values.reshape(-1,1))\n",
    "\n",
    "x_data_norm = scaler_x.transform(x_data) # 2차원\n",
    "t_data_norm = scaler_t.transform(t_data.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# 2차원 형태인데 나중에 1차원으로 사용되어야 해요..그래서 ravel() 사용.\n",
    "    \n",
    "\n",
    "# 4. 종속변수(Ozone)에 대한 결측치는 KNN을 이용해서 예측값으로 imputation할 꺼예요!\n",
    "#    학습에 사용될 x_data_train_norm , t_data_train_norm을 구해야 해요!\n",
    "x_data_train_norm = x_data_norm[~np.isnan(t_data_norm)]\n",
    "t_data_train_norm = t_data_norm[~np.isnan(t_data_norm)]\n",
    "\n",
    "# KNN 모델 생성 후 학습진행\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_regressor.fit(x_data_train_norm,t_data_train_norm)\n",
    "\n",
    "# knn_predict\n",
    "knn_predict = knn_regressor.predict(x_data_norm[np.isnan(t_data_norm)])\n",
    "t_data_norm[np.isnan(t_data_norm)] = knn_predict\n",
    "\n",
    "# 최종 데이터를 생성했어요!\n",
    "# x_data_norm\n",
    "# t_data_norm\n",
    "\n",
    "##########################################\n",
    "# 학습을 진행해 보아요! Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "test_data = [[310, 15, 80]]  # 테스트 데이터!! Ozone 량을 예측해 보아요!\n",
    "\n",
    "# sklearn\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(x_data_norm,t_data_norm)\n",
    "result = sklearn_model.predict(scaler_x.transform(test_data)).reshape(-1,1)\n",
    "\n",
    "scaled_result = scaler_t.inverse_transform(result)\n",
    "print('sklearn의 결과 : {}'.format(scaled_result))\n",
    "\n",
    "# Tensorflow 2.x\n",
    "# 모델생성\n",
    "keras_model = Sequential()\n",
    "# 레이어 추가\n",
    "keras_model.add(Flatten(input_shape=(3,)))  # input layer\n",
    "keras_model.add(Dense(1, activation='linear'))  # output layer\n",
    "\n",
    "# compile\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='mse')\n",
    "\n",
    "# 학습\n",
    "keras_model.fit(x_data_norm,\n",
    "                t_data_norm,\n",
    "                epochs=5000,\n",
    "                verbose=0)\n",
    "\n",
    "#prediction\n",
    "result = keras_model.predict(scaler_x.transform(test_data)).reshape(-1,1)\n",
    "\n",
    "scaled_result = scaler_t.inverse_transform(result)\n",
    "print('tensorflow의 결과 : {}'.format(scaled_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "Embarked    0\n",
      "Family      0\n",
      "dtype: int64\n",
      "sklearn의 정확도는 : 0.7947761194029851\n",
      "268/268 [==============================] - 0s 28us/sample - loss: 0.4974 - accuracy: 0.8022\n",
      "TF2.0의 정확도는 : [0.49743343200256573, 0.8022388]\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression에 대해서 sklearn과 Tensorflow 2.x 구현을 \n",
    "## 해볼꺼예요!!\n",
    "## titanic(kaggle) => logistic문제 (결측치가 다수있어요!!)\n",
    "## feature engineering\n",
    "\n",
    "## 데이터를 완전히 준비하는건 여러분들이 해보세요!\n",
    "## 데이터 준비가 끝나면 저랑같이 구현하는 부분만 해 보아요!!\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('~/notebook_dir/data/titanic/train.csv')\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# 필요없는 column 삭제\n",
    "\n",
    "df = df.drop(['PassengerId','Name','Ticket','Cabin','Fare'], axis=1, inplace=False)\n",
    "\n",
    "# 하나로 합칠 수 있는 column 처리\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df.drop(['SibSp','Parch'], axis=1, inplace=True)\n",
    "\n",
    "# 문자로 되어 있는 column을 숫자로 변환\n",
    "sex_dict = { 'male' : 0, 'female' : 1 }\n",
    "df['Sex'] = df['Sex'].map(sex_dict)\n",
    "\n",
    "embarked_dict = {'S' : 0, 'C' : 1, 'Q' : 2}\n",
    "df['Embarked'] = df['Embarked'].map(embarked_dict)\n",
    "\n",
    "# # 결측치 처리\n",
    "# Age에 177개의 결측치, Embarked에 결측치 2\n",
    "# Age는 median, Embarked는 mode를 이용하여 결측치 처리\n",
    "df.loc[df['Age'].isnull(),'Age'] = np.nanmedian(df['Age'].values)\n",
    "\n",
    "mode_result = stats.mode(df['Embarked'],nan_policy='omit')[0].ravel()\n",
    "# print('mode_result : {}'.format(mode_result))\n",
    "df.loc[df['Embarked'].isnull(),'Embarked'] = mode_result[0]\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 이상치 확인\n",
    "# zscore = 1.8\n",
    "\n",
    "# for col in df.columns:\n",
    "#     outliers = df.loc[np.abs(stats.zscore(df[col])) >= zscore,col]\n",
    "#     print('Col : {}에 이상치 : {}개'.format(col,outliers.sum()))\n",
    "#     print('outliers : {}'.format(outliers))\n",
    "# 실제로 이상치가 검출되지만 사실값이기 때문에 수정하지 않음.\n",
    "\n",
    "def age_category(age):\n",
    "    if ((age >=0) & (age<25)):\n",
    "        return 0\n",
    "    elif ((age >=25) & (age<50)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['Age'] = df['Age'].map(age_category)    \n",
    "\n",
    "#################################################\n",
    "\n",
    "df\n",
    "# data split\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('Survived', axis=1, inplace=False), df['Survived'], test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train\n",
    "del x_data_test\n",
    "\n",
    "##################\n",
    "\n",
    "# sklearn으로 모델 구현\n",
    "sklearn_model = LogisticRegression()    # model 생성\n",
    "sklearn_model.fit(x_data_train_norm,t_data_train)  # model 학습\n",
    "sklearn_result = sklearn_model.score(x_data_test_norm,t_data_test)\n",
    "\n",
    "print('sklearn의 정확도는 : {}'.format(sklearn_result))\n",
    "\n",
    "# tensorflow 2.x로 구현\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(x_data_train_norm.shape[1],)))\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-3),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "result = keras_model.fit(x_data_train_norm,\n",
    "                         t_data_train,\n",
    "                         epochs=1000,\n",
    "                         verbose=0,\n",
    "                         validation_split=0.3)\n",
    "\n",
    "keras_result = keras_model.evaluate(x_data_test_norm,t_data_test)\n",
    "print('TF2.0의 정확도는 : {}'.format(keras_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(result.history.keys())\n",
    "\n",
    "plt.plot(result.history['accuracy'], color='b')\n",
    "plt.plot(result.history['val_accuracy'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "sklearn result :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1242\n",
      "           1       0.95      0.97      0.96      1429\n",
      "           2       0.92      0.90      0.91      1276\n",
      "           3       0.91      0.90      0.90      1298\n",
      "           4       0.92      0.92      0.92      1236\n",
      "           5       0.88      0.88      0.88      1119\n",
      "           6       0.93      0.95      0.94      1243\n",
      "           7       0.94      0.93      0.94      1334\n",
      "           8       0.89      0.88      0.88      1204\n",
      "           9       0.89      0.89      0.89      1219\n",
      "\n",
      "    accuracy                           0.92     12600\n",
      "   macro avg       0.92      0.92      0.92     12600\n",
      "weighted avg       0.92      0.92      0.92     12600\n",
      "\n",
      "12600/12600 [==============================] - 0s 26us/sample - loss: 0.2882 - sparse_categorical_accuracy: 0.9198\n",
      "[0.28819649872325714, 0.9197619]\n",
      "tensorflow result :\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classification에 대해서\n",
    "# sklearn과 TF 2.x의 구현을 해 보아요!\n",
    "# MNIST예제를 이용해서 구현해 보아요!!!\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression  # multinomial 구현도 이걸 이용\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('/Users/mac/notebook_dir/data/digit-recognizer/numtrain.csv')\n",
    "\n",
    "# 결측치나 이상치는 없어요!!\n",
    "# Feature Engineering 할 필요가 없어요!!\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False)\n",
    "t_data = df['label']   # one-hot encoding해야하는데 일단 안할꺼예요!!\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,t_data,test_size=0.3, random_state=0)\n",
    "\n",
    "# 데이터 준비가 끝났어요!! 이제 학습을 진행해 보아요!\n",
    "sklearn_model = LogisticRegression(solver='saga')\n",
    "# solver라는 개념이 있는데 default로 사용되는건 lbfgs라는 놈이예요!\n",
    "# lbfgs : 작은 데이터셋에 좋아요!, 데이터량이 많으면 성능이 별로예요!\n",
    "# 데이터량이 많은 경우 sag(Stochastic Average Gradient Descent)를 사용하면 더 좋아요\n",
    "# 일반적으로 또 이걸 개량한 saga를 더 많이 이용해요!\n",
    "\n",
    "sklearn_model.fit(x_data_train,t_data_train)  # 학습진행\n",
    "print('sklearn result :')\n",
    "print(classification_report(t_data_test, \n",
    "                            sklearn_model.predict(x_data_test)))\n",
    "\n",
    "# TF 2.0 구현\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(x_data_train.shape[1],)))\n",
    "keras_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = keras_model.fit(x_data_train,\n",
    "                          t_data_train,\n",
    "                          epochs=500,\n",
    "                          batch_size=100,\n",
    "                          verbose=0,\n",
    "                          validation_split=0.3)\n",
    "\n",
    "print(keras_model.evaluate(x_data_test,t_data_test))\n",
    "print('tensorflow result :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-916eaf6c7a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(classification_report(t_data_test, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(t_data_test, \n",
    "                            (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n",
    "\n",
    "# (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history.history.keys()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='b')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn result :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1242\n",
      "           1       0.95      0.97      0.96      1429\n",
      "           2       0.92      0.90      0.91      1276\n",
      "           3       0.91      0.90      0.90      1298\n",
      "           4       0.92      0.92      0.92      1236\n",
      "           5       0.88      0.88      0.88      1119\n",
      "           6       0.93      0.95      0.94      1243\n",
      "           7       0.94      0.93      0.94      1334\n",
      "           8       0.89      0.88      0.88      1204\n",
      "           9       0.89      0.89      0.89      1219\n",
      "\n",
      "    accuracy                           0.92     12600\n",
      "   macro avg       0.92      0.92      0.92     12600\n",
      "weighted avg       0.92      0.92      0.92     12600\n",
      "\n",
      "12600/12600 [==============================] - 0s 30us/sample - loss: 1.8521 - sparse_categorical_accuracy: 0.1121\n",
      "[1.852106507619222, 0.11206349]\n",
      "tensorflow result :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1242\n",
      "           1       0.00      0.00      0.00      1429\n",
      "           2       0.32      0.15      0.21      1276\n",
      "           3       0.00      0.00      0.00      1298\n",
      "           4       0.00      0.00      0.00      1236\n",
      "           5       0.00      0.00      0.00      1119\n",
      "           6       0.00      0.00      0.00      1243\n",
      "           7       0.00      0.00      0.00      1334\n",
      "           8       0.00      0.00      0.00      1204\n",
      "           9       0.10      1.00      0.18      1219\n",
      "\n",
      "    accuracy                           0.11     12600\n",
      "   macro avg       0.04      0.12      0.04     12600\n",
      "weighted avg       0.04      0.11      0.04     12600\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multinomial Classification에 대해서\n",
    "# sklearn과 TF 2.x의 구현을 해 보아요!\n",
    "# MNIST예제를 이용해서 구현해 보아요!!!\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression  # multinomial 구현도 이걸 이용\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('/Users/mac/notebook_dir/data/digit-recognizer/numtrain.csv')\n",
    "\n",
    "# 결측치나 이상치는 없어요!!\n",
    "# Feature Engineering 할 필요가 없어요!!\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False)\n",
    "t_data = df['label']   # one-hot encoding해야하는데 일단 안할꺼예요!!\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,t_data,test_size=0.3, random_state=0)\n",
    "\n",
    "# 데이터 준비가 끝났어요!! 이제 학습을 진행해 보아요!\n",
    "sklearn_model = LogisticRegression(solver='saga')\n",
    "# solver라는 개념이 있는데 default로 사용되는건 lbfgs라는 놈이예요!\n",
    "# lbfgs : 작은 데이터셋에 좋아요!, 데이터량이 많으면 성능이 별로예요!\n",
    "# 데이터량이 많은 경우 sag(Stochastic Average Gradient Descent)를 사용하면 더 좋아요\n",
    "# 일반적으로 또 이걸 개량한 saga를 더 많이 이용해요!\n",
    "\n",
    "sklearn_model.fit(x_data_train,t_data_train)  # 학습진행\n",
    "print('sklearn result :')\n",
    "print(classification_report(t_data_test, \n",
    "                            sklearn_model.predict(x_data_test)))\n",
    "\n",
    "# TF 2.0 구현\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(x_data_train.shape[1],)))\n",
    "keras_model.add(Dense(10, activation='relu'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = keras_model.fit(x_data_train,\n",
    "                          t_data_train,\n",
    "                          epochs=500,\n",
    "                          batch_size=100,\n",
    "                          verbose=0,\n",
    "                          validation_split=0.3)\n",
    "\n",
    "print(keras_model.evaluate(x_data_test,t_data_test))\n",
    "print('tensorflow result :')\n",
    "print(classification_report(t_data_test, \n",
    "                            (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n",
    "\n",
    "# (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history.history.keys()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='b')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='r')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
