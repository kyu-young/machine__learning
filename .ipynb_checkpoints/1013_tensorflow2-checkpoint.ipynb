{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn의 결과 : [[38.75927452]]\n",
      "tensorflow의 결과 : [[38.881004]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats   # 이상치 처리를 위해서 필요\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')  # warning 출력을 하지 않아요!\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('/Users/mac/notebook_dir/data/ozone.csv')\n",
    "\n",
    "taining_data = df\n",
    "\n",
    "x_data = taining_data[['Solar.R','Wind','Temp']]\n",
    "t_data = taining_data['Ozone']\n",
    "\n",
    "# 결측치 확인\n",
    "# 1. 독립변수에 대한 결측치 처리부터 하고 갈께요!!\n",
    "#    Solar.R에 7개의 결측치가 있는데 median으로 처리할께요!\n",
    "for col in x_data.columns:\n",
    "    col_median = np.nanmedian(x_data[col])\n",
    "    x_data[col].loc[x_data[col].isnull()] = col_median\n",
    "    \n",
    "# 2. 독립변수에 대한 이상치를 검출한 후 이 이상치는 mean처리할께요!\n",
    "zscore = 1.8\n",
    "\n",
    "for col in x_data.columns:\n",
    "    outliers = x_data[col][np.abs(stats.zscore(x_data[col])) > zscore]\n",
    "    col_mean = np.mean(x_data.loc[~x_data[col].isin(outliers),col])\n",
    "    x_data.loc[x_data[col].isin(outliers),col] = col_mean\n",
    "\n",
    "# 3. 정규화를 진행해요!\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_t = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(x_data.values)\n",
    "scaler_t.fit(t_data.values.reshape(-1,1))\n",
    "\n",
    "x_data_norm = scaler_x.transform(x_data) # 2차원\n",
    "t_data_norm = scaler_t.transform(t_data.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# 2차원 형태인데 나중에 1차원으로 사용되어야 해요..그래서 ravel() 사용.\n",
    "    \n",
    "\n",
    "# 4. 종속변수(Ozone)에 대한 결측치는 KNN을 이용해서 예측값으로 imputation할 꺼예요!\n",
    "#    학습에 사용될 x_data_train_norm , t_data_train_norm을 구해야 해요!\n",
    "x_data_train_norm = x_data_norm[~np.isnan(t_data_norm)]\n",
    "t_data_train_norm = t_data_norm[~np.isnan(t_data_norm)]\n",
    "\n",
    "# KNN 모델 생성 후 학습진행\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_regressor.fit(x_data_train_norm,t_data_train_norm)\n",
    "\n",
    "# knn_predict\n",
    "knn_predict = knn_regressor.predict(x_data_norm[np.isnan(t_data_norm)])\n",
    "t_data_norm[np.isnan(t_data_norm)] = knn_predict\n",
    "\n",
    "# 최종 데이터를 생성했어요!\n",
    "# x_data_norm\n",
    "# t_data_norm\n",
    "\n",
    "##########################################\n",
    "# 학습을 진행해 보아요! Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "test_data = [[310, 15, 80]]  # 테스트 데이터!! Ozone 량을 예측해 보아요!\n",
    "\n",
    "# sklearn\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(x_data_norm,t_data_norm)\n",
    "result = sklearn_model.predict(scaler_x.transform(test_data)).reshape(-1,1)\n",
    "\n",
    "scaled_result = scaler_t.inverse_transform(result)\n",
    "print('sklearn의 결과 : {}'.format(scaled_result))\n",
    "\n",
    "# Tensorflow 2.x\n",
    "# 모델생성\n",
    "keras_model = Sequential()\n",
    "# 레이어 추가\n",
    "keras_model.add(Flatten(input_shape=(3,)))  # input layer\n",
    "keras_model.add(Dense(1, activation='linear'))  # output layer\n",
    "\n",
    "# compile\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='mse')\n",
    "\n",
    "# 학습\n",
    "keras_model.fit(x_data_norm,\n",
    "                t_data_norm,\n",
    "                epochs=5000,\n",
    "                verbose=0)\n",
    "\n",
    "#prediction\n",
    "result = keras_model.predict(scaler_x.transform(test_data)).reshape(-1,1)\n",
    "\n",
    "scaled_result = scaler_t.inverse_transform(result)\n",
    "print('tensorflow의 결과 : {}'.format(scaled_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "Embarked    0\n",
      "Family      0\n",
      "dtype: int64\n",
      "sklearn의 정확도는 : 0.7947761194029851\n",
      "268/268 [==============================] - 0s 28us/sample - loss: 0.4974 - accuracy: 0.8022\n",
      "TF2.0의 정확도는 : [0.49743343200256573, 0.8022388]\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression에 대해서 sklearn과 Tensorflow 2.x 구현을 \n",
    "## 해볼꺼예요!!\n",
    "## titanic(kaggle) => logistic문제 (결측치가 다수있어요!!)\n",
    "## feature engineering\n",
    "\n",
    "## 데이터를 완전히 준비하는건 여러분들이 해보세요!\n",
    "## 데이터 준비가 끝나면 저랑같이 구현하는 부분만 해 보아요!!\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('~/notebook_dir/data/titanic/train.csv')\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# 필요없는 column 삭제\n",
    "\n",
    "df = df.drop(['PassengerId','Name','Ticket','Cabin','Fare'], axis=1, inplace=False)\n",
    "\n",
    "# 하나로 합칠 수 있는 column 처리\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df.drop(['SibSp','Parch'], axis=1, inplace=True)\n",
    "\n",
    "# 문자로 되어 있는 column을 숫자로 변환\n",
    "sex_dict = { 'male' : 0, 'female' : 1 }\n",
    "df['Sex'] = df['Sex'].map(sex_dict)\n",
    "\n",
    "embarked_dict = {'S' : 0, 'C' : 1, 'Q' : 2}\n",
    "df['Embarked'] = df['Embarked'].map(embarked_dict)\n",
    "\n",
    "# # 결측치 처리\n",
    "# Age에 177개의 결측치, Embarked에 결측치 2\n",
    "# Age는 median, Embarked는 mode를 이용하여 결측치 처리\n",
    "df.loc[df['Age'].isnull(),'Age'] = np.nanmedian(df['Age'].values)\n",
    "\n",
    "mode_result = stats.mode(df['Embarked'],nan_policy='omit')[0].ravel()\n",
    "# print('mode_result : {}'.format(mode_result))\n",
    "df.loc[df['Embarked'].isnull(),'Embarked'] = mode_result[0]\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 이상치 확인\n",
    "# zscore = 1.8\n",
    "\n",
    "# for col in df.columns:\n",
    "#     outliers = df.loc[np.abs(stats.zscore(df[col])) >= zscore,col]\n",
    "#     print('Col : {}에 이상치 : {}개'.format(col,outliers.sum()))\n",
    "#     print('outliers : {}'.format(outliers))\n",
    "# 실제로 이상치가 검출되지만 사실값이기 때문에 수정하지 않음.\n",
    "\n",
    "def age_category(age):\n",
    "    if ((age >=0) & (age<25)):\n",
    "        return 0\n",
    "    elif ((age >=25) & (age<50)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['Age'] = df['Age'].map(age_category)    \n",
    "\n",
    "#################################################\n",
    "\n",
    "df\n",
    "# data split\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('Survived', axis=1, inplace=False), df['Survived'], test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train\n",
    "del x_data_test\n",
    "\n",
    "##################\n",
    "\n",
    "# sklearn으로 모델 구현\n",
    "sklearn_model = LogisticRegression()    # model 생성\n",
    "sklearn_model.fit(x_data_train_norm,t_data_train)  # model 학습\n",
    "sklearn_result = sklearn_model.score(x_data_test_norm,t_data_test)\n",
    "\n",
    "print('sklearn의 정확도는 : {}'.format(sklearn_result))\n",
    "\n",
    "# tensorflow 2.x로 구현\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(x_data_train_norm.shape[1],)))\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-3),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "result = keras_model.fit(x_data_train_norm,\n",
    "                         t_data_train,\n",
    "                         epochs=1000,\n",
    "                         verbose=0,\n",
    "                         validation_split=0.3)\n",
    "\n",
    "keras_result = keras_model.evaluate(x_data_test_norm,t_data_test)\n",
    "print('TF2.0의 정확도는 : {}'.format(keras_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(result.history.keys())\n",
    "\n",
    "plt.plot(result.history['accuracy'], color='b')\n",
    "plt.plot(result.history['val_accuracy'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "sklearn result :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1242\n",
      "           1       0.95      0.97      0.96      1429\n",
      "           2       0.92      0.90      0.91      1276\n",
      "           3       0.91      0.90      0.90      1298\n",
      "           4       0.92      0.92      0.92      1236\n",
      "           5       0.88      0.88      0.88      1119\n",
      "           6       0.93      0.95      0.94      1243\n",
      "           7       0.94      0.93      0.94      1334\n",
      "           8       0.89      0.88      0.88      1204\n",
      "           9       0.89      0.89      0.89      1219\n",
      "\n",
      "    accuracy                           0.92     12600\n",
      "   macro avg       0.92      0.92      0.92     12600\n",
      "weighted avg       0.92      0.92      0.92     12600\n",
      "\n",
      "12600/12600 [==============================] - 0s 26us/sample - loss: 0.2882 - sparse_categorical_accuracy: 0.9198\n",
      "[0.28819649872325714, 0.9197619]\n",
      "tensorflow result :\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classification에 대해서\n",
    "# sklearn과 TF 2.x의 구현을 해 보아요!\n",
    "# MNIST예제를 이용해서 구현해 보아요!!!\n",
    "\n",
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression  # multinomial 구현도 이걸 이용\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('/Users/mac/notebook_dir/data/digit-recognizer/numtrain.csv')\n",
    "\n",
    "# 결측치나 이상치는 없어요!!\n",
    "# Feature Engineering 할 필요가 없어요!!\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False)\n",
    "t_data = df['label']   # one-hot encoding해야하는데 일단 안할꺼예요!!\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,t_data,test_size=0.3, random_state=0)\n",
    "\n",
    "# 데이터 준비가 끝났어요!! 이제 학습을 진행해 보아요!\n",
    "sklearn_model = LogisticRegression(solver='saga')\n",
    "# solver라는 개념이 있는데 default로 사용되는건 lbfgs라는 놈이예요!\n",
    "# lbfgs : 작은 데이터셋에 좋아요!, 데이터량이 많으면 성능이 별로예요!\n",
    "# 데이터량이 많은 경우 sag(Stochastic Average Gradient Descent)를 사용하면 더 좋아요\n",
    "# 일반적으로 또 이걸 개량한 saga를 더 많이 이용해요!\n",
    "\n",
    "sklearn_model.fit(x_data_train,t_data_train)  # 학습진행\n",
    "print('sklearn result :')\n",
    "print(classification_report(t_data_test, \n",
    "                            sklearn_model.predict(x_data_test)))\n",
    "\n",
    "# TF 2.0 구현\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(x_data_train.shape[1],)))\n",
    "keras_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history = keras_model.fit(x_data_train,\n",
    "                          t_data_train,\n",
    "                          epochs=500,\n",
    "                          batch_size=100,\n",
    "                          verbose=0,\n",
    "                          validation_split=0.3)\n",
    "\n",
    "print(keras_model.evaluate(x_data_test,t_data_test))\n",
    "print('tensorflow result :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-916eaf6c7a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(classification_report(t_data_test, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(t_data_test, \n",
    "                            (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n",
    "\n",
    "# (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history.history.keys()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='b')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
